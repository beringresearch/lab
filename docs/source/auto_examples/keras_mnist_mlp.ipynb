{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nRunning Keras models with Tensorboard\n=====================================\n\nLab integrates into a typical keras workflow.\n\nWARNING: model persistence in Keras can be complicated, especially when\nworking with complext models. It is recommended to checkpoint each training\nepoch independently from Lab's ``log_model`` API.abs\n\nBering by creating a new Lab Project:\n\n    >>> echo \"keras\" > requirements.txt\n    >>> lab init --name simple-keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import TensorBoard\n\nimport tempfile\n\nfrom sklearn.metrics import accuracy_score, precision_score\n\nfrom lab.experiment import Experiment\n\nbatch_size = 128\nnum_classes = 10\nepochs = 20\n\n# the data, split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.reshape(60000, 784)\nx_test = x_test.reshape(10000, 784)\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Dense(512, activation='relu', input_shape=(784,)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=RMSprop(),\n              metrics=['accuracy'])\n\ne = Experiment()\n\n\n@e.start_run\ndef train():\n\n    # Create a temporary directory for tensorboard logs\n    output_dir = tempfile.mkdtemp()\n    print(\"Writing TensorBoard events locally to %s\\n\" % output_dir)\n    tensorboard = TensorBoard(log_dir=output_dir)\n\n    # During Experiment execution, tensorboard can be viewed through:\n    # tensorboard --logdir=[output_dir]\n\n    model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              verbose=1,\n              validation_data=(x_test, y_test),\n              callbacks=[tensorboard])\n\n    y_prob = model.predict(x_test)\n    y_classes = y_prob.argmax(axis=-1)\n    actual = y_test.argmax(axis=-1)\n\n    accuracy = accuracy_score(y_true=actual, y_pred=y_classes)\n    precision = precision_score(y_true=actual, y_pred=y_classes,\n                                average='macro')\n\n    # Log tensorboard\n    e.log_artifacts('tensorboard', output_dir)\n\n    # Log all metrics\n    e.log_metric('accuracy_score', accuracy)\n    e.log_metric('precision_score', precision)\n\n    # Log parameters\n    e.log_parameter('batch_size', batch_size)\n\n    # Save model\n    e.log_model('mnist-mlp', model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}